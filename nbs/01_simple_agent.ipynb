{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85671824",
   "metadata": {},
   "source": [
    "# Introduction to Building LLM Agents with Tools and Tracing\n",
    "\n",
    "<!--- @wandbcode{bedrock-webinar-July-2025} -->\n",
    "\n",
    "This script walks through the process of building a simple LLM-powered agent that can use tools (functions) to answer questions. We'll cover:\n",
    "1. Making basic LLM calls.\n",
    "2. Introducing Weave for tracing and observability.\n",
    "3. Defining tools for the LLM (manually and automatically).\n",
    "4. Implementing a basic agentic loop.\n",
    "5. Structuring the agent using Python classes.\n",
    "6. Running the agent on a multi-step task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803fbc4f",
   "metadata": {},
   "source": [
    "**Prerequisites:**\n",
    "Make sure you have the necessary libraries installed:\n",
    "```bash\n",
    "!pip install weave requests openai\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d103af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Configuration & Setup\n",
    "import inspect\n",
    "import json\n",
    "import requests\n",
    "import weave # Must import weave before litellm for auto-patching\n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.pretty import pprint\n",
    "from openai import OpenAI\n",
    "from exa_py import Exa\n",
    "from typing import Any, Callable, Dict, List, get_type_hints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf6667",
   "metadata": {},
   "source": [
    "Define a model to use, as we are going to use tool calling you need a capable model like `mistral-large`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8874a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# Set the model name you want to use globally.\n",
    "\n",
    "MODEL = \"gpt-4.1\"\n",
    "\n",
    "oai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "exa_client = Exa(api_key=os.getenv(\"EXA_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48c55be",
   "metadata": {},
   "source": [
    "Let's log to [W&B Weave](https://weave-docs.wandb.ai/). Weights & Biases (W&B) Weave is a framework for tracking, experimenting with, evaluating, deploying, and improving LLM-based applications. Designed for flexibility and scalability, Weave supports every stage of your LLM application development workflow:\n",
    "\n",
    "- Tracing & Monitoring: Track LLM calls and application logic to debug and analyze production systems.\n",
    "- Systematic Iteration: Refine and iterate on prompts, datasets, and models.\n",
    "- Experimentation: Experiment with different models and prompts in the LLM Playground.\n",
    "- Evaluation: Use custom or pre-built scorers alongside our comparison tools to systematically assess and enhance application performance.\n",
    "- Guardrails: Protect your application with pre- and post-safeguards for content moderation, prompt safety, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70b57d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: capecape.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/capecape/london-workshop-2025/weave\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<weave.trace.weave_client.WeaveClient at 0x13cd82150>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: retry_attempt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a Weave project. Traces will be sent here.\n",
    "# You can view them in the Weave UI (usually runs locally).\n",
    "weave.init('london-workshop-2025')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13266e05",
   "metadata": {},
   "source": [
    "## 1. Basic LLM Call with OpenAI SDK\n",
    "\n",
    "Let's start with a simple call to the LLM using/\n",
    "\n",
    "![](images/01_trace.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9ec1b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebd9-4968-744b-97ba-f19157ba782b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\\nHello! Great question. An **AI agent** is a system designed to perceive its environment, process information, and take actions to achieve specific goals, often autonomously. Hereâ€™s a simple breakdown of **how an AI agent works**:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Perception (Input)**\n",
      "\n",
      "- The agent senses its environment using sensors. These \"sensors\" could take many forms:\n",
      "  - In a self-driving car: cameras, RADAR, LIDAR.\n",
      "  - In a chess engine: the state of the chessboard.\n",
      "  - In a chatbot: text input from a user.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **Processing (Thinking/Decision-Making)**\n",
      "\n",
      "- The agent interprets the inputs using algorithms and models. This stage might involve:\n",
      "  - Recognizing patterns,\n",
      "  - Predicting outcomes,\n",
      "  - Planning a sequence of actions.\n",
      "- **AI techniques** used here:\n",
      "  - Rule-based logic,\n",
      "  - Machine learning,\n",
      "  - Reinforcement learning,\n",
      "  - Deep learning.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Action (Output)**\n",
      "\n",
      "- The agent acts upon the environment via \"actuators\" or communication.\n",
      "  - A robot moves its arms,\n",
      "  - A chatbot responds with text,\n",
      "  - A recommendation system suggests a product.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **Feedback & Learning**\n",
      "\n",
      "- Many AI agents are capable of learning from experience (feedback from previous actions) to improve future performance.\n",
      "  - Trial-and-error (reinforcement learning),\n",
      "  - Updating models based on new data.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example: AI Agent in a Game**\n",
      "\n",
      "1. **Perceives** the current game board,\n",
      "2. **Processes** all possible moves and predicts outcomes,\n",
      "3. **Acts** by choosing the best move,\n",
      "4. **Learns** by adjusting strategies after each game.\n",
      "\n",
      "---\n",
      "\n",
      "**In summary:**  \n",
      "An AI agent is an autonomous entity that observes its environment, processes information, decides what to do, takes action, and (sometimes) learns from its actions to get better over time.\n",
      "\n",
      "If youâ€™d like more technical details or examples, feel free to ask!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebd9-dcbd-7543-8131-7f61d0869f45\n"
     ]
    }
   ],
   "source": [
    "# Define a simple message list (conversation history)\n",
    "messages = [{\"role\": \"user\", \"content\": \"Hello, LLM! How does an AI agent work?\"}]\n",
    "\n",
    "# Make the call\n",
    "response = resp = oai_client.chat.completions.create(\n",
    "    model = MODEL,\n",
    "    messages=messages,\n",
    ")\n",
    "# Print the response content\n",
    "assistant_response = response.choices[0].message.content\n",
    "print(f\"LLM Response:\\\\n{assistant_response}\")\n",
    "\n",
    "# Click on the ðŸ© linke below to see the trace in Weave ðŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795ead84",
   "metadata": {},
   "source": [
    "Because we imported `weave` and called `weave.init()`, the OpenAI SDK call above was automatically traced. You can open your Weave dashboard and see the trace, including the input messages, output response, latency, model used, etc. This is invaluable for debugging and monitoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb90b937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Great question.\n",
      "\n",
      "An **AI agent** is a system that perceives its environment and takes actions to achieve specific goals. Here's how it works in general terms:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Perception**\n",
      "- The agent **receives information** about the environment through sensors or inputs (these could be cameras, text, audio, etc., depending on the application).\n",
      "\n",
      "### 2. **Processing/Reasoning**\n",
      "- It **processes** this information, using algorithms and models (such as machine learning models or decision trees), to **reason** about what is happening in the environment.\n",
      "- The agent often has some decision-making module that determines the best action to take based on its current knowledge and objectives.\n",
      "\n",
      "### 3. **Action**\n",
      "- The agent **acts** upon the environment through effectors (outputs, actuators, or other user-facing actions).\n",
      "- The action is meant to change the environment in a way that helps the agent reach its goals.\n",
      "\n",
      "### 4. **Learning & Adaptation (for intelligent agents)**\n",
      "- Many AI agents can **learn** from their experiences to improve their strategies over time (using methods like reinforcement learning).\n",
      "- They might update their models or policies based on feedback about the success or failure of their actions.\n",
      "\n",
      "---\n",
      "\n",
      "### **Types of AI Agents**\n",
      "\n",
      "- **Simple reflex agents**: Respond directly to perceptions (if \"X\" see \"Y\", do \"Z\").\n",
      "- **Model-based agents**: Build an internal model of the world to make better decisions.\n",
      "- **Goal-based agents**: Take actions to achieve specific goals.\n",
      "- **Utility-based agents**: Seek actions that maximize a given utility or reward function.\n",
      "- **Learning agents**: Continuously improve their performance through learning.\n",
      "\n",
      "---\n",
      "\n",
      "### **Example**\n",
      "- **Self-driving Car AI Agent**:\n",
      "    1. **Perceives**: Reads sensor data about the car's surroundings.\n",
      "    2. **Processes**: Calculates the best route and actions to avoid obstacles.\n",
      "    3. **Acts**: Controls the steering, speed, and brakes.\n",
      "    4. **Learns**: Updates its models based on driving experience.\n",
      "\n",
      "---\n",
      "\n",
      "**In summary:**  \n",
      "An AI agent senses the world, thinks about what to do, acts to change the world, and (if sophisticated) learns to get better over time.\n",
      "\n",
      "Feel free to ask about specific types of AI agents or examples!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebda-2144-7ea3-8b84-b5245724b7e3\n"
     ]
    }
   ],
   "source": [
    "# most of the time you would want to define your own operations to trace, for instance to call the model.\n",
    "# You just need to add the @weave.op decorator to the function and it will be traced.\n",
    "\n",
    "@weave.op\n",
    "def call_model(model_name: str, messages: List[Dict[str, Any]], **kwargs) -> str:\n",
    "    \"Call a model with the given messages and kwargs.\"\n",
    "    response = oai_client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message\n",
    "\n",
    "response = call_model(model_name=MODEL, messages=messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e97c8b6",
   "metadata": {},
   "source": [
    "![](images/02_nested_trace.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75409570",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Introducing Tool Calling\n",
    "\n",
    "Agents become much more powerful when they can use **tools** â€“ external functions or APIs â€“ to get information or perform actions beyond the LLM's internal knowledge. To allow an LLM to use a tool, we need to provide it with a description (schema) of the tool, including its name, purpose, and expected arguments.\n",
    "\n",
    "Check the Mistral docs for function calling: https://platform.openai.com/docs/guides/function-calling\n",
    "\n",
    "![](images/function-calling-diagram-steps.png)\n",
    "\n",
    "First, let's define a simple Python function we want the LLM to be able to call. We add `@weave.op` to trace when this function actually gets executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ede106b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op \n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers.\n",
    "    Args:\n",
    "        a: The first number.\n",
    "        b: The second number.\n",
    "    \"\"\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a691123a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebda-1469-72fb-9cab-f94ffe970c31\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebeb-4743-7fc8-86fa-00da4ee94f5f\n"
     ]
    }
   ],
   "source": [
    "add_numbers(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffcbfd9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type function is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# this doesn't work...\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mcall_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43madd_numbers\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/weave/trace/op.py:1244\u001b[39m, in \u001b[36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:\n\u001b[32m-> \u001b[39m\u001b[32m1244\u001b[39m     res, _ = \u001b[43m_call_sync_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__should_raise\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(R, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/weave/trace/op.py:501\u001b[39m, in \u001b[36m_call_sync_func\u001b[39m\u001b[34m(op, __weave, __should_raise, __require_explicit_finish, *args, **kwargs)\u001b[39m\n\u001b[32m    498\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    503\u001b[39m     finish(exception=e)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(model_name, messages, **kwargs)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;129m@weave\u001b[39m.op\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, messages: List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], **kwargs) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCall a model with the given messages and kwargs.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     response = \u001b[43moai_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/weave/trace/op.py:1244\u001b[39m, in \u001b[36mop.<locals>.op_deco.<locals>.create_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1242\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:\n\u001b[32m-> \u001b[39m\u001b[32m1244\u001b[39m     res, _ = \u001b[43m_call_sync_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__should_raise\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(R, res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/weave/trace/op.py:501\u001b[39m, in \u001b[36m_call_sync_func\u001b[39m\u001b[34m(op, __weave, __should_raise, __require_explicit_finish, *args, **kwargs)\u001b[39m\n\u001b[32m    498\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    503\u001b[39m     finish(exception=e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/weave/integrations/openai/openai_sdk.py:420\u001b[39m, in \u001b[36mcreate_wrapper_sync.<locals>.wrapper.<locals>._add_stream_options.<locals>._wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m urlparse(base_url).hostname == \u001b[33m\"\u001b[39m\u001b[33mapi.openai.com\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    418\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m] = {\u001b[33m\"\u001b[39m\u001b[33minclude_usage\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:1156\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1110\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1112\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1153\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1154\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1155\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1156\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1157\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1159\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1180\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1181\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1186\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1187\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1188\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1189\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1192\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/openai/_base_client.py:968\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m    965\u001b[39m options = \u001b[38;5;28mself\u001b[39m._prepare_options(options)\n\u001b[32m    967\u001b[39m remaining_retries = max_retries - retries_taken\n\u001b[32m--> \u001b[39m\u001b[32m968\u001b[39m request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[38;5;28mself\u001b[39m._prepare_request(request)\n\u001b[32m    971\u001b[39m kwargs: HttpxSendArgs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/openai/_base_client.py:547\u001b[39m, in \u001b[36mBaseClient._build_request\u001b[39m\u001b[34m(self, options, retries_taken)\u001b[39m\n\u001b[32m    544\u001b[39m     kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    546\u001b[39m \u001b[38;5;66;03m# TODO: report this error to httpx\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pyright: ignore[reportUnknownMemberType]\u001b[39;49;00m\n\u001b[32m    548\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNotGiven\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the `Query` type that we use is incompatible with qs'\u001b[39;49;00m\n\u001b[32m    553\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# `Params` type as it needs to be typed as `Mapping[str, object]`\u001b[39;49;00m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# so that passing a `TypedDict` doesn't cause an error.\u001b[39;49;00m\n\u001b[32m    555\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# https://github.com/microsoft/pyright/issues/3526#event-6715453066\u001b[39;49;00m\n\u001b[32m    556\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstringify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMapping\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAny\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    557\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    558\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/httpx/_client.py:378\u001b[39m, in \u001b[36mBaseClient.build_request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, timeout, extensions)\u001b[39m\n\u001b[32m    372\u001b[39m     timeout = (\n\u001b[32m    373\u001b[39m         \u001b[38;5;28mself\u001b[39m.timeout\n\u001b[32m    374\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(timeout, UseClientDefault)\n\u001b[32m    375\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m Timeout(timeout)\n\u001b[32m    376\u001b[39m     )\n\u001b[32m    377\u001b[39m     extensions = \u001b[38;5;28mdict\u001b[39m(**extensions, timeout=timeout.as_dict())\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextensions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/httpx/_models.py:408\u001b[39m, in \u001b[36mRequest.__init__\u001b[39m\u001b[34m(self, method, url, params, headers, cookies, content, data, files, json, stream, extensions)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    407\u001b[39m     content_type: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28mself\u001b[39m.headers.get(\u001b[33m\"\u001b[39m\u001b[33mcontent-type\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m408\u001b[39m     headers, stream = \u001b[43mencode_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mboundary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_multipart_boundary_from_content_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontent_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontent_type\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    419\u001b[39m     \u001b[38;5;28mself\u001b[39m._prepare(headers)\n\u001b[32m    420\u001b[39m     \u001b[38;5;28mself\u001b[39m.stream = stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/httpx/_content.py:216\u001b[39m, in \u001b[36mencode_request\u001b[39m\u001b[34m(content, data, files, json, boundary)\u001b[39m\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m encode_urlencoded_data(data)\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m json \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencode_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {}, ByteStream(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/deep-research-bot/.venv/lib/python3.12/site-packages/httpx/_content.py:177\u001b[39m, in \u001b[36mencode_json\u001b[39m\u001b[34m(json)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode_json\u001b[39m(json: Any) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m], ByteStream]:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     body = \u001b[43mjson_dumps\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m,\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m:\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.encode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    180\u001b[39m     content_length = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(body))\n\u001b[32m    181\u001b[39m     content_type = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/json/__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/json/encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/json/encoder.py:258\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    254\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    255\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, \u001b[38;5;28mself\u001b[39m.indent, floatstr,\n\u001b[32m    256\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    257\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.9-macos-aarch64-none/lib/python3.12/json/encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type function is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# this doesn't work...\n",
    "call_model(model_name=MODEL, messages=messages, tools=[add_numbers])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b082a58a",
   "metadata": {},
   "source": [
    "> We need to manually create the JSON schema describing this tool in a format that models *Mistral* understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190a9063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define the tool schema\n",
    "tool_add_numbers_schema = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"add_numbers\",\n",
    "        \"description\": \"Adds two numbers.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"a\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The first number.\"\n",
    "                },\n",
    "                \"b\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"The second number.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"a\", \"b\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b6dfd4",
   "metadata": {},
   "source": [
    "Now, we make an LLM call, passing the `tools` parameter with our schema. We ask a question that should trigger the tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e7d2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebda-4aad-7eeb-ab34-55fa2178c7a6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessageFunctionToolCall</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'call_giOIUin7kZmrbKhwjNzDEMdC'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">function</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Function</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"a\":77,\"b\":11}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'add_numbers'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[1;35mChatCompletionMessageFunctionToolCall\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'call_giOIUin7kZmrbKhwjNzDEMdC'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mfunction\u001b[0m=\u001b[1;35mFunction\u001b[0m\u001b[1m(\u001b[0m\u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"a\":77,\"b\":11\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'add_numbers'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'function'\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant use tools to answer questions.\"},\n",
    "    {\"role\": \"user\", \"content\": \"My lucky numbers are 77 and 11. What is their sum?\"}]\n",
    "response = call_model(model_name=MODEL, messages=messages, tools=[tool_add_numbers_schema])\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092fdded",
   "metadata": {},
   "source": [
    "## Manual Tool Call\n",
    "The LLM's response might contain a request to call our tool (`response.choices[0].message.tool_calls`) or it might respond directly (`response.choices[0].message.content`). If it requests a tool call, we need to:\n",
    "\n",
    "1. Parse the arguments it provides.\n",
    "2. Execute our actual Python function (`add_numbers`) with those arguments.\n",
    "3. (In a real agent loop) Send the result back to the LLM in a new message with `role=\"tool\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f1ea6c",
   "metadata": {},
   "source": [
    "Let's manually call the tools in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8e64e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebea-9a02-7e71-9087-1f0deee0dc4f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM requested a tool call:\n",
      "  - Tool: add_numbers, Args: {\"a\":77,\"b\":11}\n",
      "88\n"
     ]
    }
   ],
   "source": [
    "if response.tool_calls:\n",
    "    print(\"LLM requested a tool call:\")\n",
    "    for tool_call in response.tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args_str = tool_call.function.arguments\n",
    "        function_args = json.loads(function_args_str)\n",
    "        print(f\"  - Tool: {function_name}, Args: {function_args_str}\")\n",
    "        if function_name == \"add_numbers\":\n",
    "            tool_result_content = add_numbers(**function_args)\n",
    "\n",
    "print(tool_result_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f38a9f",
   "metadata": {},
   "source": [
    "We need to add the tool call result to the messages (there is actually 2 messages to add)\n",
    "- the response from the assistant that decided to call the tool\n",
    "- the tool output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd2ca3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(response.model_dump())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d13d8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"role\": \"tool\",\n",
    "    \"name\": function_name,\n",
    "    \"content\": str(tool_result_content)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0992e3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a helpful assistant use tools to answer questions.'},\n",
       " {'role': 'user',\n",
       "  'content': 'My lucky numbers are 77 and 11. What is their sum?'},\n",
       " {'content': None,\n",
       "  'refusal': None,\n",
       "  'role': 'assistant',\n",
       "  'annotations': [],\n",
       "  'audio': None,\n",
       "  'function_call': None,\n",
       "  'tool_calls': [{'id': 'call_giOIUin7kZmrbKhwjNzDEMdC',\n",
       "    'function': {'arguments': '{\"a\":77,\"b\":11}', 'name': 'add_numbers'},\n",
       "    'type': 'function'}]},\n",
       " {'tool_call_id': 'call_giOIUin7kZmrbKhwjNzDEMdC',\n",
       "  'role': 'tool',\n",
       "  'name': 'add_numbers',\n",
       "  'content': '88'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c76bf",
   "metadata": {},
   "source": [
    "You should have a sequence of messages like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5621c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system', 'user', 'assistant', 'tool']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m[\"role\"] for m in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4b05f",
   "metadata": {},
   "source": [
    "Now call the model again with the new messages and it will use the tool call result to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbf845aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/capecape/london-workshop-2025/r/call/0199ebea-d2e2-790d-b680-c7fb0a83985e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of your lucky numbers, 77 and 11, is 88.\n"
     ]
    }
   ],
   "source": [
    "final_response = call_model(model_name=MODEL, messages=messages)\n",
    "print(final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01abc5",
   "metadata": {},
   "source": [
    "## 3. Simplifying Tool Definition with a Processor Function\n",
    "\n",
    "Manually writing JSON schemas is tedious and error-prone. We can automate this by inspecting our Python function's signature, type hints, and docstring.\n",
    "\n",
    "First, let's define a helper function (`generate_tool_schema`) that takes a Python function and generates the schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61ab93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tool_schema(func: Callable) -> dict:\n",
    "    \"\"\"Given a Python function, generate a tool-compatible JSON schema.\n",
    "    Handles basic types and Enums. Assumes docstrings are formatted for arg descriptions.\n",
    "    \"\"\"\n",
    "    signature = inspect.signature(func)\n",
    "    parameters = signature.parameters\n",
    "    type_hints = get_type_hints(func)\n",
    "\n",
    "    schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": inspect.getdoc(func).split(\"\\\\n\")[0] if inspect.getdoc(func) else \"\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {},\n",
    "                \"required\": [],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    docstring = inspect.getdoc(func)\n",
    "    param_descriptions = {}\n",
    "    if docstring:\n",
    "        args_section = False\n",
    "        current_param = None\n",
    "        for line in docstring.split('\\\\n'):\n",
    "            line_stripped = line.strip()\n",
    "            if line_stripped.lower().startswith((\"args:\", \"arguments:\", \"parameters:\")):\n",
    "                args_section = True\n",
    "                continue\n",
    "            if args_section:\n",
    "                if \":\" in line_stripped:\n",
    "                    param_name, desc = line_stripped.split(\":\", 1)\n",
    "                    param_descriptions[param_name.strip()] = desc.strip()\n",
    "                elif line_stripped and not line_stripped.startswith(\" \"): # Heuristic: end of args section\n",
    "                     args_section = False\n",
    "\n",
    "    for name, param in parameters.items():\n",
    "        is_required = param.default == inspect.Parameter.empty\n",
    "        param_type = type_hints.get(name, Any)\n",
    "        json_type = \"string\"\n",
    "        param_schema = {}\n",
    "\n",
    "        # Basic type mapping\n",
    "        if param_type == str: json_type = \"string\"\n",
    "        elif param_type == int: json_type = \"integer\"\n",
    "        elif param_type == float: json_type = \"number\"\n",
    "        elif param_type == bool: json_type = \"boolean\"\n",
    "        elif hasattr(param_type, '__origin__') and param_type.__origin__ is list: # Handle List[type]\n",
    "             item_type = param_type.__args__[0] if param_type.__args__ else Any\n",
    "             if item_type == str: param_schema = {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "             elif item_type == int: param_schema = {\"type\": \"array\", \"items\": {\"type\": \"integer\"}}\n",
    "             # Add more list item types if needed\n",
    "             else: param_schema = {\"type\": \"array\", \"items\": {\"type\": \"string\"}} # Default list item type\n",
    "        elif hasattr(param_type, \"__members__\") and issubclass(param_type, Enum): # Handle Enum\n",
    "             json_type = \"string\"\n",
    "             param_schema[\"enum\"] = [e.value for e in param_type]\n",
    "\n",
    "        if not param_schema: # If not set by List or Enum\n",
    "            param_schema[\"type\"] = json_type\n",
    "\n",
    "        param_schema[\"description\"] = param_descriptions.get(name, \"\")\n",
    "\n",
    "        if param.default != inspect.Parameter.empty and param.default is not None:\n",
    "             param_schema[\"default\"] = param.default # Note: OpenAI schema doesn't officially use default, but useful metadata\n",
    "\n",
    "        schema[\"function\"][\"parameters\"][\"properties\"][name] = param_schema\n",
    "        if is_required:\n",
    "            schema[\"function\"][\"parameters\"][\"required\"].append(name)\n",
    "    return schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d193839",
   "metadata": {},
   "source": [
    "Now we can use this function to automatically generate the schema for our tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "187d550c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'add_numbers'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Adds two numbers.\\nArgs:\\n    a: The first number.\\n    b: The second number.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'integer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'integer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'add_numbers'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'Adds two numbers.\\nArgs:\\n    a: The first number.\\n    b: The second number.'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'integer'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m''\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[32m'b'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'integer'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m''\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'a'\u001b[0m, \u001b[32m'b'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tool_schema = generate_tool_schema(add_numbers)\n",
    "pprint(tool_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867416e",
   "metadata": {},
   "source": [
    "Now, we define a `function_tool` \"processor\". This isn't a decorator in the `@` syntax sense here, but a function that we call *after* defining our tool function. It uses `generate_tool_schema` to attach the schema to the function object itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "015ed9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_tool(func: Callable) -> Callable:\n",
    "    \"\"\"Attaches a tool schema to the function and marks it as a tool.\n",
    "    Call this *after* defining your function: my_func = function_tool(my_func)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        func.tool_schema = generate_tool_schema(func)\n",
    "        func.is_tool = True # Mark it as a tool\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing tool {func.__name__}: {e}\")\n",
    "        # Optionally raise or mark as failed\n",
    "        func.tool_schema = None\n",
    "        func.is_tool = False\n",
    "    return func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504243c6",
   "metadata": {},
   "source": [
    "We can use this function to automatically generate the schema for our tool, as a decorator or after the function is defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c424f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'add_numbers'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Adds two numbers.\\nArgs:\\n    a: The first number.\\n    b: The second number.'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'parameters'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'object'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'properties'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'integer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'b'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'integer'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'description'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">''</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #008000; text-decoration-color: #008000\">'required'</span>: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'a'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'b'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'function'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[32m'function'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'name'\u001b[0m: \u001b[32m'add_numbers'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'description'\u001b[0m: \u001b[32m'Adds two numbers.\\nArgs:\\n    a: The first number.\\n    b: The second number.'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[32m'parameters'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'object'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[32m'properties'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[32m'a'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'integer'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m''\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   â”‚   \u001b[0m\u001b[32m'b'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'integer'\u001b[0m, \u001b[32m'description'\u001b[0m: \u001b[32m''\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[32m'required'\u001b[0m: \u001b[1m[\u001b[0m\u001b[32m'a'\u001b[0m, \u001b[32m'b'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_numbers = function_tool(add_numbers)\n",
    "pprint(add_numbers.tool_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c651811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'add_numbers',\n",
       "  'description': 'Adds two numbers.\\nArgs:\\n    a: The first number.\\n    b: The second number.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'integer', 'description': ''},\n",
       "    'b': {'type': 'integer', 'description': ''}},\n",
       "   'required': ['a', 'b']}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_numbers.tool_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7280921",
   "metadata": {},
   "source": [
    "and call the tool =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70bd946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_numbers(1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ef16e",
   "metadata": {},
   "source": [
    "### 3.1 Real Example using an API based tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5227a8a9",
   "metadata": {},
   "source": [
    "We are going to use the EXA search API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op \n",
    "@function_tool # <- we can use the decorator to automatically generate the tool schema\n",
    "def exa_search(query: str) -> Dict[str, Any]:\n",
    "    return exa_client.search_and_contents(query=query, type='auto', highlights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af6c3b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'function',\n",
       " 'function': {'name': 'get_pokemon_info',\n",
       "  'description': 'Fetches minimal information (name, ID, weight) for a specific Pokemon. Weight is in hectograms.\\n\\nArgs:\\n    pokemon_name: The name or Pokedex ID of the Pokemon.',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'pokemon_name': {'type': 'string', 'description': ''}},\n",
       "   'required': ['pokemon_name']}}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pokemon_info.tool_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fb22b679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Pikachu', 'id': 25, 'weight': 60}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pokemon_info(\"pikachu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a073e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">refusal</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">role</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'assistant'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">annotations</span>=<span style=\"font-weight: bold\">[]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">audio</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">function_call</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">tool_calls</span>=<span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ChatCompletionMessageToolCall</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'call_rFTZ2BbkpVMd4G7yqS6nysA4'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">function</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Function</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">arguments</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'{\"pokemon_name\":\"Pikachu\"}'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'get_pokemon_info'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   â”‚   </span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'function'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   â”‚   </span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">â”‚   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mChatCompletionMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mcontent\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mrefusal\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mrole\u001b[0m=\u001b[32m'assistant'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mannotations\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33maudio\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mfunction_call\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[1;35mChatCompletionMessageToolCall\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mid\u001b[0m=\u001b[32m'call_rFTZ2BbkpVMd4G7yqS6nysA4'\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mfunction\u001b[0m=\u001b[1;35mFunction\u001b[0m\u001b[1m(\u001b[0m\u001b[33marguments\u001b[0m=\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\"pokemon_name\":\"Pikachu\"\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[33mname\u001b[0m=\u001b[32m'get_pokemon_info'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32mâ”‚   â”‚   â”‚   \u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'function'\u001b[0m\n",
       "\u001b[2;32mâ”‚   â”‚   \u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[2;32mâ”‚   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that can use tools to answer questions.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the weight of Pikachu?\"}]\n",
    "\n",
    "response = call_model(model_name=OPENAI_SMALL_MODEL, messages=messages, tools=[get_pokemon_info.tool_schema])\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7350625",
   "metadata": {},
   "source": [
    "Let's create some helper functions to perform the tool calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0938e29b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai.types.function_tool_call'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[53]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunction_tool_call\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionToolCall\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tool\u001b[39m(tools: \u001b[38;5;28mlist\u001b[39m[Callable], name: \u001b[38;5;28mstr\u001b[39m) -> Callable:\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'openai.types.function_tool_call'"
     ]
    }
   ],
   "source": [
    "from openai.types.\n",
    "\n",
    "def get_tool(tools: list[Callable], name: str) -> Callable:\n",
    "    for t in tools:\n",
    "        if t.__name__ == name:\n",
    "            return t\n",
    "    raise KeyError(f\"No tool with name {name} found\")\n",
    "\n",
    "def perform_tool_calls(tools: list[Callable], tool_calls: list[FunctionToolCall]) -> list[dict]:\n",
    "    \"Perform the tool calls and return the messages with the tool call results\"\n",
    "    messages = []\n",
    "    for tool_call in tool_calls:\n",
    "        print(f\"Performing tool call: {tool_call.function.name}\")\n",
    "        print(f\"  - Args: {tool_call.function.arguments}\")\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        tool = get_tool(tools, function_name)\n",
    "        tool_response = tool(**function_args)\n",
    "        print(f\"  - Response: {tool_response}\")\n",
    "        messages.append({\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": str(tool_response),\n",
    "        })\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c5881ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"Pikachu\"}\n",
      "  - Response: {'name': 'Pikachu', 'id': 25, 'weight': 60}\n",
      "Pikachu weighs 60 pounds.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# add the tool call result to the messages\n",
    "messages.append(response.model_dump())\n",
    "messages.extend(perform_tool_calls(tools=[get_pokemon_info], tool_calls=response.tool_calls))\n",
    "\n",
    "final_response = call_model(model_name=MISTRAL_SMALL_MODEL, messages=messages)\n",
    "print(final_response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3956939",
   "metadata": {},
   "source": [
    "Let's wrap this in a function and add a few more tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10ab1b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def pokedex(pokemon_question: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that can use tools to answer questions.\"},\n",
    "        {\"role\": \"user\", \"content\": pokemon_question}]\n",
    "\n",
    "    # call model with tools\n",
    "    response = call_model(\n",
    "        model_name=MISTRAL_SMALL_MODEL, \n",
    "        messages=messages, \n",
    "        tools=[get_pokemon_info.tool_schema, \n",
    "            add_numbers.tool_schema])\n",
    "\n",
    "    # add the response to the messages\n",
    "    messages.append(response.model_dump())\n",
    "\n",
    "    # perform the tool calls\n",
    "    messages.extend(perform_tool_calls(tools=[get_pokemon_info, add_numbers], tool_calls=response.tool_calls))\n",
    "\n",
    "    final_response = call_model(model_name=MISTRAL_SMALL_MODEL, messages=messages)\n",
    "    return final_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bc0183b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"pikachu\"}\n",
      "  - Response: {'name': 'Pikachu', 'id': 25, 'weight': 60}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"caterpie\"}\n",
      "  - Response: {'name': 'Caterpie', 'id': 10, 'weight': 29}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"butterfree\"}\n",
      "  - Response: {'name': 'Butterfree', 'id': 12, 'weight': 320}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The combined weight of Ash's first 3 PokÃ©mon is 409 units.\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokedex(\"What is the combined weight of Ash's first 3 pokemons?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedaa4a4",
   "metadata": {},
   "source": [
    "![](images/04_pokedex.png)\n",
    "\n",
    "This is \"Almost\" an agent, but it's missing the loop. Let's add that next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd890f5",
   "metadata": {},
   "source": [
    "## 4. Implementing a Basic Agentic Loop\n",
    "\n",
    "Let's implement a basic agentic loop. We'll use the `pokedex` function we just created. The implementation we have above has some limitations:\n",
    "- Its a single turn, so if it fails to answer my question in one pass it is over.\n",
    "\n",
    "![](images/05_agent.png)\n",
    "\n",
    "From the really good [Anthropic Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents) article and encourage people to read it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1737003e",
   "metadata": {},
   "source": [
    "A simple for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63bc2975",
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op\n",
    "def pokedex_loop(pokemon_question: str, max_turns: int = 4, tools = [get_pokemon_info, add_numbers]) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that can use tools to answer questions.\"},\n",
    "        {\"role\": \"user\", \"content\": pokemon_question}]\n",
    "\n",
    "    \n",
    "    for turn in range(max_turns):\n",
    "        print(f\"--- Agent Loop Turn {turn + 1}/{max_turns} ---\")\n",
    "\n",
    "        # call model with tools\n",
    "        response = call_model(\n",
    "            model_name=MISTRAL_SMALL_MODEL, \n",
    "            messages=messages, \n",
    "            tools=[t.tool_schema for t in tools])\n",
    "\n",
    "        # add the response to the messages\n",
    "        messages.append(response.model_dump())\n",
    "\n",
    "        # if the LLM requested tool calls, perform them\n",
    "        if response.tool_calls:\n",
    "            print(\"LLM requested tool calls:\")\n",
    "            # perform the tool calls\n",
    "            tool_outputs = perform_tool_calls(tools=[get_pokemon_info, add_numbers], tool_calls=response.tool_calls)\n",
    "            messages.extend(tool_outputs)\n",
    "        # LLM gave content response\n",
    "        elif response.content:\n",
    "            print(f\"LLM content response: {response.content}\")\n",
    "            return response.content\n",
    "        else:\n",
    "            print(\"LLM response had neither content nor tool calls. Stopping loop.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fecad3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent Loop Turn 1/4 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"pikachu\"}\n",
      "  - Response: {'name': 'Pikachu', 'id': 25, 'weight': 60}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"caterpie\"}\n",
      "  - Response: {'name': 'Caterpie', 'id': 10, 'weight': 29}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"pidgey\"}\n",
      "  - Response: {'name': 'Pidgey', 'id': 16, 'weight': 18}\n",
      "--- Agent Loop Turn 2/4 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: add_numbers\n",
      "  - Args: {\"a\": 60, \"b\": 29}\n",
      "  - Response: 89\n",
      "Performing tool call: add_numbers\n",
      "  - Args: {\"a\": 60, \"b\": 18}\n",
      "  - Response: 78\n",
      "--- Agent Loop Turn 3/4 ---\n",
      "LLM content response: The combined weight of Ash's first 3 pokemons is 167 hectograms.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The combined weight of Ash's first 3 pokemons is 167 hectograms.\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokedex_loop(\"What is the combined weight of Ash's first 3 pokemons?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "83e96dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent Loop Turn 1/4 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"pikachu\"}\n",
      "  - Response: {'name': 'Pikachu', 'id': 25, 'weight': 60}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"caterpie\"}\n",
      "  - Response: {'name': 'Caterpie', 'id': 10, 'weight': 29}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"pidgey\"}\n",
      "  - Response: {'name': 'Pidgey', 'id': 16, 'weight': 18}\n",
      "--- Agent Loop Turn 2/4 ---\n",
      "LLM content response: Ash's first three PokÃ©mon are Pikachu, Caterpie, and Pidgey. Their combined weight is 107 hectograms.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Ash's first three PokÃ©mon are Pikachu, Caterpie, and Pidgey. Their combined weight is 107 hectograms.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokedex_loop(\"Name Ash's first 3 pokemons and calculate their combined weight?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c031bde",
   "metadata": {},
   "source": [
    "![](images/06_pokedex_loop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a3967",
   "metadata": {},
   "source": [
    "This one is kind of an hallucination, I was expecting snorlax to be the heaviest pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba8cf35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent Loop Turn 1/4 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"1\"}\n",
      "  - Response: {'name': 'Bulbasaur', 'id': 1, 'weight': 69}\n",
      "--- Agent Loop Turn 2/4 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"2\"}\n",
      "  - Response: {'name': 'Ivysaur', 'id': 2, 'weight': 130}\n",
      "--- Agent Loop Turn 3/4 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"3\"}\n",
      "  - Response: {'name': 'Venusaur', 'id': 3, 'weight': 1000}\n",
      "--- Agent Loop Turn 4/4 ---\n",
      "LLM content response: The heaviest pokemon is Venusaur, with a weight of 1000 hectograms.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The heaviest pokemon is Venusaur, with a weight of 1000 hectograms.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pokedex_loop(\"Which is the heaviest pokemon?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e589c3",
   "metadata": {},
   "source": [
    "6. Structuring the Agent with Classes\n",
    "\n",
    "The loop above works, but for more complex agents, encapsulating the logic and state within classes is much better. We'll define:\n",
    "- `AgentState`: A Pydantic model to hold the conversation history and potentially other state.\n",
    "- `SimpleAgent`: A class containing the agent's configuration (model, system message, tools) and logic (`step`, `run`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "31f65412",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(BaseModel):\n",
    "    \"\"\"Manages the state of the agent.\"\"\"\n",
    "    messages: List[Dict[str, Any]] = Field(default_factory=list)\n",
    "    step: int = Field(default=0)\n",
    "    final_assistant_content: str | None = None # Populated at the end of a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26f57c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAgent:\n",
    "    \"\"\"A simple agent class with tracing, state, and tool processing.\"\"\"\n",
    "    def __init__(self, model_name: str, system_message: str, tools: List[Callable]):\n",
    "        self.model_name = model_name\n",
    "        self.system_message = system_message\n",
    "        self.tools = [function_tool(t) for t in tools] # add schemas to the tools\n",
    "    \n",
    "    @weave.op(name=\"SimpleAgent.step\") # Trace each step\n",
    "    def step(self, state: AgentState) -> AgentState:\n",
    "        step = state.step + 1\n",
    "        messages = state.messages\n",
    "        final_assistant_content = None\n",
    "        try:\n",
    "            # call model with tools\n",
    "            response = call_model(\n",
    "                model_name=self.model_name, \n",
    "                messages=messages, \n",
    "                tools=[t.tool_schema for t in self.tools])\n",
    "\n",
    "            # add the response to the messages\n",
    "            messages.append(response.model_dump())\n",
    "\n",
    "            # if the LLM requested tool calls, perform them\n",
    "            if response.tool_calls:\n",
    "                print(\"LLM requested tool calls:\")\n",
    "                # perform the tool calls\n",
    "                tool_outputs = perform_tool_calls(tools=[get_pokemon_info, add_numbers], tool_calls=response.tool_calls)\n",
    "                messages.extend(tool_outputs)\n",
    "\n",
    "            # LLM gave content response\n",
    "            else:\n",
    "                messages.append(response.model_dump())\n",
    "                final_assistant_content = response.content\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR in Agent Step: {e}\")\n",
    "            # Add an error message to history to indicate failure\n",
    "            messages.append({\"role\": \"assistant\", \"content\": f\"Agent error in step: {str(e)}\"})\n",
    "            final_assistant_content = f\"Agent error in step {step}: {str(e)}\"\n",
    "        return AgentState(messages=messages, step=step, final_assistant_content=final_assistant_content)\n",
    "\n",
    "    @weave.op(name=\"SimpleAgent.run\")\n",
    "    def run(self, user_prompt: str, max_turns: int = 10) -> AgentState:\n",
    "        state = AgentState(messages=[\n",
    "            {\"role\": \"system\", \"content\": self.system_message},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}])\n",
    "        for _ in range(max_turns):\n",
    "            print(f\"--- Agent Loop Turn {state.step}/{max_turns} ---\")\n",
    "            state = self.step(state)\n",
    "            if state.final_assistant_content:\n",
    "                return state\n",
    "        return state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80842566",
   "metadata": {},
   "source": [
    "![](images/07_simple_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6b40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Agent Loop Turn 0/10 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"Pikachu\"}\n",
      "  - Response: {'name': 'Pikachu', 'id': 25, 'weight': 60}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"Caterpie\"}\n",
      "  - Response: {'name': 'Caterpie', 'id': 10, 'weight': 29}\n",
      "Performing tool call: get_pokemon_info\n",
      "  - Args: {\"pokemon_name\": \"Pidgey\"}\n",
      "  - Response: {'name': 'Pidgey', 'id': 16, 'weight': 18}\n",
      "--- Agent Loop Turn 1/10 ---\n",
      "LLM requested tool calls:\n",
      "Performing tool call: add_numbers\n",
      "  - Args: {\"a\": 60, \"b\": 29}\n",
      "  - Response: 89\n",
      "Performing tool call: add_numbers\n",
      "  - Args: {\"a\": 60, \"b\": 18}\n",
      "  - Response: 78\n",
      "--- Agent Loop Turn 2/10 ---\n",
      "The combined weight of Ash's first 3 pokemons is 89 + 78 = 167 hectograms.\n"
     ]
    }
   ],
   "source": [
    "agent = SimpleAgent(\n",
    "    model_name=MISTRAL_SMALL_MODEL,\n",
    "    system_message=\"You are a helpful assistant that can use tools to answer questions.\",\n",
    "    tools=[get_pokemon_info, add_numbers]\n",
    ")\n",
    "state = agent.run(user_prompt=\"What is the combined weight of Ash's first 3 pokemons?\")\n",
    "print(f\"Final response: {state.final_assistant_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9cd3c5",
   "metadata": {},
   "source": [
    "Possible improvements to the SimpleAgent:\n",
    "- Give the model info about the state of the conversation, you could inject a message with the model context pressure, steps left, etc.\n",
    "- Structured output. Make the model output a specific format, for instance a JSON with the expected fields.\n",
    "- Add more tools like read and write files, access a database.\n",
    "- Agent handoff: Agent1 does triage and Agent2 executes specific tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe0fe5e",
   "metadata": {},
   "source": [
    "## 10. A more complex agent: Researcher\n",
    "\n",
    "This agent is a research assistant that can help with the research process. It can:\n",
    "- Retrieve relevant documents from a database\n",
    "- Critique your manuscript with different personalities\n",
    "- Read and write files\n",
    "- List files in a directory\n",
    "\n",
    "Let me show you how it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6457129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from researcher.main import main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
