{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08955a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.eval import run_evaluation\n",
    "from evaluation.eval_config import EvalConfig\n",
    "import weave\n",
    "\n",
    "@weave.op\n",
    "def my_agent(query: str) -> str:\n",
    "    return \"Space is cool\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77378c9a",
   "metadata": {},
   "source": [
    "# Debug Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd9f71d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dataset rows constructed for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: morgan.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/morgan/london-workshop-2025/weave\n",
      "INFO:weave.trace.init_message:Logged in as Weights & Biases user: morgan.\n",
      "View Weave data at https://wandb.ai/morgan/london-workshop-2025/weave\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Error getting code deps for <function Evaluation.summarize at 0x115f4ad40>: invalid syntax (<unknown>, line 6)\n",
      "INFO:weave.trace.serialization.op_type:Error getting code deps for <function Evaluation.summarize at 0x115f4ad40>: invalid syntax (<unknown>, line 6)\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: 🍩 https://wandb.ai/morgan/london-workshop-2025/r/call/0199f704-f529-7e3c-91e7-f169863e81c6\n",
      "INFO:weave.trace.weave_client:🍩 https://wandb.ai/morgan/london-workshop-2025/r/call/0199f704-f529-7e3c-91e7-f169863e81c6\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Evaluated 1 of 2 examples\n",
      "INFO:weave.evaluation.eval:Evaluated 1 of 2 examples\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Evaluated 2 of 2 examples\n",
      "INFO:weave.evaluation.eval:Evaluated 2 of 2 examples\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Evaluation summary {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   \"output\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"row_index\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"mean\": 0.5\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"trial_index\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"mean\": 0.0\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"id\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"mean\": 51.5\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     }\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   \"deep_research_scores\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"comprehensiveness\": 0.0,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"insight\": 0.0,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"instruction_following\": 0.0,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"readability\": 0.0,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"overall\": 0.0\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   \"model_latency\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"mean\": 0.0004050731658935547\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   }\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: }\n",
      "INFO:weave.evaluation.eval:Evaluation summary {\n",
      "  \"output\": {\n",
      "    \"row_index\": {\n",
      "      \"mean\": 0.5\n",
      "    },\n",
      "    \"trial_index\": {\n",
      "      \"mean\": 0.0\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"mean\": 51.5\n",
      "    }\n",
      "  },\n",
      "  \"deep_research_scores\": {\n",
      "    \"comprehensiveness\": 0.0,\n",
      "    \"insight\": 0.0,\n",
      "    \"instruction_following\": 0.0,\n",
      "    \"readability\": 0.0,\n",
      "    \"overall\": 0.0\n",
      "  },\n",
      "  \"model_latency\": {\n",
      "    \"mean\": 0.0004050731658935547\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m eval_config = EvalConfig(debug=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results, summary = \u001b[38;5;28;01mawait\u001b[39;00m run_evaluation(\n\u001b[32m      4\u001b[39m     eval_config=eval_config,\n\u001b[32m      5\u001b[39m     agent_callable=my_agent,\n\u001b[32m      6\u001b[39m )\n\u001b[32m      7\u001b[39m results, summary\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "eval_config = EvalConfig(debug=True)\n",
    "\n",
    "results = await run_evaluation(\n",
    "    eval_config=eval_config,\n",
    "    agent_callable=my_agent,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3063735",
   "metadata": {},
   "source": [
    "# Full Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb28710",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_config = EvalConfig(\n",
    "    evaluation_name=\"test_dummy_agent\",\n",
    "    trials=3,\n",
    "    weave_parallelism=40,\n",
    ")\n",
    "\n",
    "results = await run_evaluation(\n",
    "    eval_config=eval_config,\n",
    "    agent_callable=my_agent,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4b4049",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
