{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08955a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 dataset rows constructed for evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1mweave\u001b[0m: Logged in as Weights & Biases user: morgan.\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: View Weave data at https://wandb.ai/morgan/london-workshop-2025/weave\n",
      "INFO:weave.trace.init_message:Logged in as Weights & Biases user: morgan.\n",
      "View Weave data at https://wandb.ai/morgan/london-workshop-2025/weave\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: ðŸ© https://wandb.ai/morgan/london-workshop-2025/r/call/0199f2e4-bc74-75d7-9a35-088be6420d1a\n",
      "INFO:weave.trace.weave_client:ðŸ© https://wandb.ai/morgan/london-workshop-2025/r/call/0199f2e4-bc74-75d7-9a35-088be6420d1a\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Evaluated 1 of 2 examples\n",
      "INFO:weave.evaluation.eval:Evaluated 1 of 2 examples\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Evaluated 2 of 2 examples\n",
      "INFO:weave.evaluation.eval:Evaluated 2 of 2 examples\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: Evaluation summary {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   \"output\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"row_index\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"mean\": 0.5\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"trial_index\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"mean\": 0.0\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"id\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"mean\": 51.5\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"criteria\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"id\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         \"mean\": 51.5\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       \"dimension_weight\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         \"readability\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:           \"mean\": 0.14\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         \"insight\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:           \"mean\": 0.36\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         \"comprehensiveness\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:           \"mean\": 0.31\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         \"instruction_following\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:           \"mean\": 0.19\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:         }\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:       }\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     }\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   \"deep_research_scores\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"comprehensiveness\": 0.0,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"insight\": 0.0,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"instruction_following\": 0.0,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"readability\": 0.1334282099936749,\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"overall\": 0.02133758096512172\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   },\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   \"model_latency\": {\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:     \"mean\": 0.00021588802337646484\n",
      "\u001b[36m\u001b[1mweave\u001b[0m:   }\n",
      "\u001b[36m\u001b[1mweave\u001b[0m: }\n",
      "INFO:weave.evaluation.eval:Evaluation summary {\n",
      "  \"output\": {\n",
      "    \"row_index\": {\n",
      "      \"mean\": 0.5\n",
      "    },\n",
      "    \"trial_index\": {\n",
      "      \"mean\": 0.0\n",
      "    },\n",
      "    \"id\": {\n",
      "      \"mean\": 51.5\n",
      "    },\n",
      "    \"criteria\": {\n",
      "      \"id\": {\n",
      "        \"mean\": 51.5\n",
      "      },\n",
      "      \"dimension_weight\": {\n",
      "        \"readability\": {\n",
      "          \"mean\": 0.14\n",
      "        },\n",
      "        \"insight\": {\n",
      "          \"mean\": 0.36\n",
      "        },\n",
      "        \"comprehensiveness\": {\n",
      "          \"mean\": 0.31\n",
      "        },\n",
      "        \"instruction_following\": {\n",
      "          \"mean\": 0.19\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"deep_research_scores\": {\n",
      "    \"comprehensiveness\": 0.0,\n",
      "    \"insight\": 0.0,\n",
      "    \"instruction_following\": 0.0,\n",
      "    \"readability\": 0.1334282099936749,\n",
      "    \"overall\": 0.02133758096512172\n",
      "  },\n",
      "  \"model_latency\": {\n",
      "    \"mean\": 0.00021588802337646484\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "4 validation errors for JudgeOutput\ncomprehensiveness\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ninsight\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ninstruction_following\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nreadability\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mSpace is cool\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m eval_config = EvalConfig(debug=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m results, summary = \u001b[38;5;28;01mawait\u001b[39;00m run_evaluation(\n\u001b[32m     14\u001b[39m     args=eval_config,\n\u001b[32m     15\u001b[39m     agent_callable=my_agent,\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m results, summary\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML/deep-research-bot/evaluation/eval.py:876\u001b[39m, in \u001b[36mrun_evaluation.<locals>._evaluate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    870\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m evaluation.evaluate(\n\u001b[32m    871\u001b[39m         model,\n\u001b[32m    872\u001b[39m         __weave={\u001b[33m\"\u001b[39m\u001b[33mdisplay_name\u001b[39m\u001b[33m\"\u001b[39m: args.evaluation_name},  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[32m    873\u001b[39m     )\n\u001b[32m    875\u001b[39m outputs = model._outputs\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m results = \u001b[43moutputs_to_evaluation_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_rows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    877\u001b[39m results.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m res: res.id \u001b[38;5;28;01mif\u001b[39;00m res.id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1e9\u001b[39m)\n\u001b[32m    878\u001b[39m aggregated_summary = aggregate_results(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML/deep-research-bot/evaluation/eval.py:709\u001b[39m, in \u001b[36moutputs_to_evaluation_results\u001b[39m\u001b[34m(outputs, dataset_rows)\u001b[39m\n\u001b[32m    696\u001b[39m         normalized = compute_normalized_scores(output.get(\u001b[33m\"\u001b[39m\u001b[33mweighted_scores\u001b[39m\u001b[33m\"\u001b[39m, {}))\n\u001b[32m    697\u001b[39m     judge_output_dict = output.get(\u001b[33m\"\u001b[39m\u001b[33mjudge_output\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m    698\u001b[39m     results.append(\n\u001b[32m    699\u001b[39m         EvaluationResult(\n\u001b[32m    700\u001b[39m             \u001b[38;5;28mid\u001b[39m=dataset_row[\u001b[33m\"\u001b[39m\u001b[33mrow_id\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    701\u001b[39m             prompt=dataset_row[\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    702\u001b[39m             comprehensiveness=\u001b[38;5;28mfloat\u001b[39m(normalized.get(\u001b[33m\"\u001b[39m\u001b[33mcomprehensiveness\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m    703\u001b[39m             insight=\u001b[38;5;28mfloat\u001b[39m(normalized.get(\u001b[33m\"\u001b[39m\u001b[33minsight\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m    704\u001b[39m             instruction_following=\u001b[38;5;28mfloat\u001b[39m(\n\u001b[32m    705\u001b[39m                 normalized.get(\u001b[33m\"\u001b[39m\u001b[33minstruction_following\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)\n\u001b[32m    706\u001b[39m             ),\n\u001b[32m    707\u001b[39m             readability=\u001b[38;5;28mfloat\u001b[39m(normalized.get(\u001b[33m\"\u001b[39m\u001b[33mreadability\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m    708\u001b[39m             overall_score=\u001b[38;5;28mfloat\u001b[39m(normalized.get(\u001b[33m\"\u001b[39m\u001b[33moverall\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.0\u001b[39m)),\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m             raw_judge=\u001b[43mJudgeOutput\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjudge_output_dict\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    710\u001b[39m         )\n\u001b[32m    711\u001b[39m     )\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ML/deep-research-bot/.venv/lib/python3.12/site-packages/pydantic/main.py:705\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    699\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    701\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    702\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    703\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m705\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 4 validation errors for JudgeOutput\ncomprehensiveness\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ninsight\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\ninstruction_following\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nreadability\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from evaluation.eval import run_evaluation\n",
    "from evaluation.eval_config import EvalConfig\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def my_agent(query: str) -> str:\n",
    "    return \"Space is cool\"\n",
    "\n",
    "eval_config = EvalConfig(debug=True)\n",
    "\n",
    "results, summary = await run_evaluation(\n",
    "    args=eval_config,\n",
    "    agent_callable=my_agent,\n",
    ")\n",
    "results, summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
